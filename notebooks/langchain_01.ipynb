{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e819a38",
   "metadata": {},
   "source": [
    "# Demo\n",
    "é¦–å…ˆé€šè¿‡.envæ–‡ä»¶å†…çš„å…¨å±€å˜é‡å®šä¹‰æ¨¡å‹è°ƒç”¨çš„APIï¼Œå¹¶é€šè¿‡`load_dotenv`å‡½æ•°è¯»å–ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9aa93c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19ffaff",
   "metadata": {},
   "source": [
    "è°ƒç”¨`langchain`ä¸­çš„ OpenAI å¼çš„æ¥å£ç”¨ deepseek çš„ API å®šä¹‰ llmã€‚\n",
    "å¹¶ä¸”ä½¿ç”¨`@tool`ä¿®é¥°å™¨å®šä¹‰ä¸€ä¸ªå·¥å…·å¹¶ç»‘å®šåˆ°æ¨¡å‹ä¸Šï¼Œæ¨¡å‹ä¼š**è‡ªå·±åˆ¤æ–­**å›ç­”æ—¶æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "179cf6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: I'll check the weather in San Francisco for you.\n",
      "Tool Calls: [{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'call_00_TzKhSL0BY0qmeYpVMgp7dLVm', 'type': 'tool_call'}]\n",
      "Content: Hello! I'm an AI assistant designed to help you with various tasks. I can provide information, answer questions, and assist with different types of requests. One of the specific capabilities I have is checking weather information for cities around the world. \n",
      "\n",
      "I'm here to help you with whatever you need - whether it's getting weather updates, answering general questions, or assisting with other tasks. How can I help you today?\n",
      "Tool Calls: []\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# ä½¿ç”¨ @tool è£…é¥°å™¨å®šä¹‰ä¸€ä¸ªå·¥å…·\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# å°†å·¥å…·ç»‘å®šåˆ°å¤§æ¨¡å‹\n",
    "llm_with_tool = llm.bind_tools([get_weather])\n",
    "\n",
    "\n",
    "# Run the agent\n",
    "response = llm_with_tool.invoke(\"what is the weather in sf\")\n",
    "print(f\"Content: {response.content}\")\n",
    "print(f\"Tool Calls: {response.tool_calls}\")\n",
    "# Content: I'll check the weather in San Francisco for you.\n",
    "# Tool Calls: [{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'call_00_y9c9mcggTEuG7FQTfac1mt0Y', 'type': 'tool_call'}]\n",
    "\n",
    "\n",
    "response = llm_with_tool.invoke(\"Hello, can you introduce yourself?\")\n",
    "print(f\"Content: {response.content}\")\n",
    "print(f\"Tool Calls: {response.tool_calls}\")\n",
    "# I'm here to help you in a friendly and informative way. What can I assist you with today?\n",
    "# Tool Calls: []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc98630",
   "metadata": {},
   "source": [
    "# é€æ­¥æ„å»º\n",
    "## 1. å®šä¹‰ç³»ç»Ÿæç¤ºç¬¦\n",
    "ä½¿ç”¨ç³»ç»Ÿæç¤ºç¬¦å®šä¹‰ agent çš„è§’è‰²å’Œè¡Œä¸ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbb11d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert weather forecaster, who speaks in puns.\n",
    "\n",
    "You have access to two tools:\n",
    "\n",
    "- get_weather_for_location: use this to get the weather for a specific location\n",
    "- get_user_location: use this to get the user's location\n",
    "\n",
    "If a user asks you for the weather, make sure you know the location. \\\n",
    "If you can tell from the question that they mean wherever they are, \\\n",
    "use the get_user_location tool to find their location.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc508105",
   "metadata": {},
   "source": [
    "## 2. å®šä¹‰å¤§æ¨¡å‹ä½¿ç”¨çš„å·¥å…·\n",
    "å·¥å…·å¯ä»¥é€šè¿‡è°ƒç”¨ä½ å®šä¹‰çš„å‡½æ•°ï¼Œè®©æ¨¡å‹ä¸å¤–éƒ¨ç³»ç»Ÿäº¤äº’ã€‚å·¥å…·å¯ä»¥ä¾èµ–è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ ï¼Œä¹Ÿå¯ä»¥ä¸ä»£ç†å†…å­˜äº¤äº’ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b605338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "# @dataclass ä¿®é¥°ç¬¦ä¼šè‡ªåŠ¨ç”Ÿæˆæ•°æ®ç±»çš„å¸¸ç”¨æ–¹æ³•ï¼š __init__ã€__repr__ã€__eq__ \n",
    "# @dataclass\n",
    "class Context:\n",
    "    \"\"\"Custom runtime context schema.\"\"\"\n",
    "    user_id: str\n",
    "\n",
    "# ToolRuntime æ˜¯è¿æ¥ LLM é€»è¾‘ å’Œ åç«¯ç³»ç»ŸçŠ¶æ€ çš„æ¡¥æ¢ã€‚\n",
    "# å®ƒå…è®¸ä½ åœ¨å·¥å…·å†…éƒ¨è®¿é—®é‚£äº› LLM æ— æ³•ç”Ÿæˆçš„ç³»ç»Ÿçº§æ•°æ®ï¼ˆå¦‚ç”¨æˆ·èº«ä»½ã€é…ç½®ä¿¡æ¯ç­‰ï¼‰ã€‚\n",
    "# langchain çœ‹åˆ°è¿™ä¸ªç±»å‹ä¹‹åï¼Œä¸ä¼šæŠŠå®ƒæš´éœ²ç»™ LLMï¼Œè€Œæ˜¯ç›´æ¥ä¼ é€’ç»™å·¥å…·å‡½æ•°ã€‚\n",
    "# å¹¶ä¸”ï¼Œlangchain è¿˜ä¼šåœ¨å·¥å…·è¢«è°ƒç”¨æ—¶è‡ªåŠ¨æŠŠå½“å‰çš„è¿è¡Œæ—¶ä¿¡æ¯æ³¨å…¥è¿›å»ã€‚\n",
    "\n",
    "@tool\n",
    "def get_user_location(config: RunnableConfig) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve user information based on user ID.\n",
    "    è¿™é‡Œä½¿ç”¨äº†æ–°çš„ RunnableConfig ç±»å‹æ¥è·å–è¿è¡Œæ—¶çš„é…ç½®ä¿¡æ¯ã€‚\n",
    "    å…¶ä¸­ç›´æ¥ä½¿ç”¨é€šç”¨çš„å­—å…¸ç»“æ„ config æ¥è·å–éœ€è¦çš„ user_idã€‚\n",
    "    ä¸å†éœ€è¦æ˜¾å¼åœ°å®šä¹‰ä¸€ä¸ª Context ç±»ã€‚\n",
    "    \"\"\"\n",
    "    # ä» config ä¸­è·å– user_id\n",
    "    # è°ƒç”¨æ—¶éœ€è¦é€šè¿‡ .invoke(..., config={\"configurable\": {\"user_id\": \"1\"}}) ä¼ å…¥\n",
    "    configuration = config.get(\"configurable\", {})\n",
    "    user_id = configuration.get(\"user_id\")\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0462c6ba",
   "metadata": {},
   "source": [
    "## 3. é…ç½®å¤§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e103d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a238b3",
   "metadata": {},
   "source": [
    "## 4. å®šä¹‰å“åº”æ ¼å¼\n",
    "å¦‚æœä½ éœ€è¦ä»£ç†å“åº”åŒ¹é…ç‰¹å®šæ¨¡å¼ï¼Œä¹Ÿå¯ä»¥é€‰æ‹©å®šä¹‰ç»“æ„åŒ–å“åº”æ ¼å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c22286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a dataclass here, but Pydantic models are also supported.\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "    # A punny response (always required)\n",
    "    punny_response: str\n",
    "    # Any interesting information about the weather if available\n",
    "    weather_conditions: str | None = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f52d6",
   "metadata": {},
   "source": [
    "## 5. æ·»åŠ å†…å­˜\n",
    "ç»™ä»£ç†æ·»åŠ å†…å­˜ä»¥ç»´æŒäº¤äº’é—´çš„çŠ¶æ€ã€‚è¿™ä½¿ä»£ç†èƒ½å¤Ÿè®°ä½ä¹‹å‰çš„å¯¹è¯å’Œä¸Šä¸‹æ–‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e340e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f77f5b9",
   "metadata": {},
   "source": [
    "## 6. åˆ›å»ºå¹¶è¿è¡Œä»£ç†\n",
    "ç»„è£…ä¹‹å‰çš„ç»„ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1de65df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qz/4hkyy7hs45d18375s1sjjyw00000gp/T/ipykernel_7260/1517482675.py:6: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent = create_react_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well, it looks like San Francisco is also living up to a sunny reputation! The forecast shows it's always sunny there too - I guess you could say the weather is \"SF-abulous\"! â˜€ï¸\n",
      "\n",
      "But seriously, if you're in San Francisco, you're in for a bright day. Just remember that even when it's sunny, you might want to bring a light jacket - you know how SF can be \"chill\" even on sunny days!\n",
      "You're welcome! I'm \"SF-astic\" that I could help! If you ever need another weather check, just \"fog-et\" about the fog and ask me anytime! Have a \"golden\" day in the Golden Gate city! ğŸŒ‰â˜€ï¸\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.structured_output import ToolStrategy\n",
    "# from langchain.agents import create_agent\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[get_user_location, get_weather_for_location],\n",
    "    prompt=SYSTEM_PROMPT,\n",
    "    checkpointer=checkpointer,\n",
    "    # response_format=ResponseFormat,\n",
    ")\n",
    "\n",
    "# `thread_id` is a unique identifier for a given conversation.\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"2\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather outside?\"}]},\n",
    "    config=config,\n",
    "    # context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "# print(response['structured_response'])\n",
    "print(response[\"messages\"][-1].content)\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"Florida is still having a 'sun-derful' day! The sunshine is playing 'ray-dio' hits all day long! I'd say it's the perfect weather for some 'solar-bration'! If you were hoping for rain, I'm afraid that idea is all 'washed up' - the forecast remains 'clear-ly' brilliant!\",\n",
    "#     weather_conditions=\"It's always sunny in Florida!\"\n",
    "# )\n",
    "\n",
    "\n",
    "# Note that we can continue the conversation using the same `thread_id`.\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"thank you!\"}]},\n",
    "    config=config,\n",
    "    # context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)\n",
    "# print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"You're 'thund-erfully' welcome! It's always a 'breeze' to help you stay 'current' with the weather. I'm just 'cloud'-ing around waiting to 'shower' you with more forecasts whenever you need them. Have a 'sun-sational' day in the Florida sunshine!\",\n",
    "#     weather_conditions=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d37dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "git-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
